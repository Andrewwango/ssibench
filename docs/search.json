[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "SSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction.\n\nAndrew Wang, Steven McDonagh, Mike Davies\n   \n\n\nSkip to…\n\nOverview\nHow to…\n\n…use the benchmark\n\n…contribute a method\n\n…use a custom dataset, model, forward operator/acquisition strategy, metric\n\n\nBenchmark results\nTraining script step-by-step\n\n\n\n\nSSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction. We contribute:\n\nA comprehensive review of state-of-the-art self-supervised feedforward methods for inverse problems;\nWell-documented implementations of all benchmarked methods in the open-source DeepInverse library, and a modular benchmark site enabling ML researchers to evaluate new methods or on custom setups and datasets;\nBenchmarking experiments on MRI, across multiple realistic, general scenarios;\nA new method, multi-operator equivariant imaging (MO-EI).\n\n\n\n\n\n\n\nFirst setup your environment:\n\nCreate a python environment:\n\npython -m venv venv\nsource venv/Scripts/activate\n\nClone the benchmark repo:\n\ngit clone https://github.com/ssibench/ssibench.git\n\nInstall DeepInverse\n\npip install deepinv\nThen run train.py for your chosen loss, where --loss is one of mc, …:\npython train.py --loss ...\nTo evaluate, use the same script train.py with 0 epochs and loading a checkpoint. We provide one pretrained model for quick eval for TODO\npython train.py --epochs 0 --ckpt \"...pt\"\nNotation: in our benchmark, we compare the loss functions \\(\\mathcal{L}(\\ldots)\\), while keeping constant the model \\(f_\\theta\\), forward operator physics \\(A\\), and data \\(y\\).\n\n\n\n\nAdd the code for your loss in the format:\n\nclass YourOwnLoss(deepinv.loss.Loss):\n    def forward(\n        self, \n        x_net: torch.Tensor,    # Reconstruction i.e. model output\n        y: torch.Tensor,        # Measurement data e.g. k-space in MRI\n        x: torch.Tensor = None, # Ground truth, must be unused!\n        model: deepinv.models.Reconstructor, # Reconstruction model $f_\\theta$\n        physics: deepinv.physics.Physics,    # Forward operator physics $A$\n        **kwargs\n    ):\n        loss_calc = ...\n        return loss_calc\n\nAdd your loss function as an option in train.py (hint: search “Add your custom loss here!”)\nOpen a GitHub pull request to contribute your loss! (hint: how to open a PR in GitHub)\n\n\n\n\nOur modular benchmark lets you easily train and evaluate the benchmarked methods on your own setup.\n\nThe custom dataset should have the form (see DeepInverse docs for details):\n\nclass YourOwnDataset(torch.utils.data.Dataset):\n    def __getitem__(self, idx: int):\n        ...\n        # y = measurement data\n        # params = dict of physics data-dependent parameters, e.g. acceleration mask in MRI\n        return     x,     y, params # If ground truth x provided for evaluation\n        return torch.nan, y, params # If ground truth does not exist\n\nReplace dataset = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nThe custom model should have the form (see DeepInverse guide for details):\n\nclass YourOwnModel(deepinv.models.Reconstructor):\n    def forward(\n        self, \n        y: torch.Tensor,\n        physics: deepinv.physics.Physics,\n        **kwargs\n    ):\n        x_net = ...\n        return x_net\n\nReplace model = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nTo use an alternative physics, you can use a different off-the-shelf DeepInverse physics or a custom one of the form (see DeepInverse guide on creating custom physics):\n\nclass YourOwnPhysics(deepinv.physics.Physics):\n    def A(self, x: torch.Tensor, **kwargs):\n        y = ...\n        return y\n    \n    def A_adjoint(self, y: torch.Tensor, **kwargs):\n        x_hat = ...\n        return x_hat\n\nReplace physics = ... train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nThe custom metric should have the form (see DeepInverse docs for details):\n\nclass YourOwnMetric(dinv.loss.metric.Metric):\n    def metric(\n        self, \n        x_net: torch.Tensor, # Reconstruction i.e. model output\n        x: torch.Tensor,     # Ground-truth for evaluation\n    ):\n        return ...\n\nReplace metric = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\n\nTODO\n\n\n\n\nstep by step python …"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "SSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction. We contribute:\n\nA comprehensive review of state-of-the-art self-supervised feedforward methods for inverse problems;\nWell-documented implementations of all benchmarked methods in the open-source DeepInverse library, and a modular benchmark site enabling ML researchers to evaluate new methods or on custom setups and datasets;\nBenchmarking experiments on MRI, across multiple realistic, general scenarios;\nA new method, multi-operator equivariant imaging (MO-EI)."
  },
  {
    "objectID": "index.html#how-to",
    "href": "index.html#how-to",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "First setup your environment:\n\nCreate a python environment:\n\npython -m venv venv\nsource venv/Scripts/activate\n\nClone the benchmark repo:\n\ngit clone https://github.com/ssibench/ssibench.git\n\nInstall DeepInverse\n\npip install deepinv\nThen run train.py for your chosen loss, where --loss is one of mc, …:\npython train.py --loss ...\nTo evaluate, use the same script train.py with 0 epochs and loading a checkpoint. We provide one pretrained model for quick eval for TODO\npython train.py --epochs 0 --ckpt \"...pt\"\nNotation: in our benchmark, we compare the loss functions \\(\\mathcal{L}(\\ldots)\\), while keeping constant the model \\(f_\\theta\\), forward operator physics \\(A\\), and data \\(y\\).\n\n\n\n\nAdd the code for your loss in the format:\n\nclass YourOwnLoss(deepinv.loss.Loss):\n    def forward(\n        self, \n        x_net: torch.Tensor,    # Reconstruction i.e. model output\n        y: torch.Tensor,        # Measurement data e.g. k-space in MRI\n        x: torch.Tensor = None, # Ground truth, must be unused!\n        model: deepinv.models.Reconstructor, # Reconstruction model $f_\\theta$\n        physics: deepinv.physics.Physics,    # Forward operator physics $A$\n        **kwargs\n    ):\n        loss_calc = ...\n        return loss_calc\n\nAdd your loss function as an option in train.py (hint: search “Add your custom loss here!”)\nOpen a GitHub pull request to contribute your loss! (hint: how to open a PR in GitHub)\n\n\n\n\nOur modular benchmark lets you easily train and evaluate the benchmarked methods on your own setup.\n\nThe custom dataset should have the form (see DeepInverse docs for details):\n\nclass YourOwnDataset(torch.utils.data.Dataset):\n    def __getitem__(self, idx: int):\n        ...\n        # y = measurement data\n        # params = dict of physics data-dependent parameters, e.g. acceleration mask in MRI\n        return     x,     y, params # If ground truth x provided for evaluation\n        return torch.nan, y, params # If ground truth does not exist\n\nReplace dataset = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nThe custom model should have the form (see DeepInverse guide for details):\n\nclass YourOwnModel(deepinv.models.Reconstructor):\n    def forward(\n        self, \n        y: torch.Tensor,\n        physics: deepinv.physics.Physics,\n        **kwargs\n    ):\n        x_net = ...\n        return x_net\n\nReplace model = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nTo use an alternative physics, you can use a different off-the-shelf DeepInverse physics or a custom one of the form (see DeepInverse guide on creating custom physics):\n\nclass YourOwnPhysics(deepinv.physics.Physics):\n    def A(self, x: torch.Tensor, **kwargs):\n        y = ...\n        return y\n    \n    def A_adjoint(self, y: torch.Tensor, **kwargs):\n        x_hat = ...\n        return x_hat\n\nReplace physics = ... train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nThe custom metric should have the form (see DeepInverse docs for details):\n\nclass YourOwnMetric(dinv.loss.metric.Metric):\n    def metric(\n        self, \n        x_net: torch.Tensor, # Reconstruction i.e. model output\n        x: torch.Tensor,     # Ground-truth for evaluation\n    ):\n        return ...\n\nReplace metric = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark."
  },
  {
    "objectID": "index.html#benchmark-results",
    "href": "index.html#benchmark-results",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "index.html#training-script-step-by-step",
    "href": "index.html#training-script-step-by-step",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "step by step python …"
  }
]