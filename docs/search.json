[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "SSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction.\n\nAndrew Wang, Steven McDonagh, Mike Davies\n   \n\n\nSkip to…\n\nOverview\nHow to…\n\n…use the benchmark\n\n…contribute a method\n\n…use a custom dataset, model, forward operator/acquisition strategy, metric\n\n\nBenchmark results\nTraining script step-by-step\n\n\n\n\nSSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction. We contribute:\n\nA comprehensive review of state-of-the-art self-supervised feedforward methods for inverse problems;\nWell-documented implementations of all benchmarked methods in the open-source DeepInverse library, and a modular benchmark site enabling ML researchers to evaluate new methods or on custom setups and datasets;\nBenchmarking experiments on MRI, across multiple realistic, general scenarios;\nA new method, multi-operator equivariant imaging (MO-EI).\n\n\n\n\n\n\n\nFirst setup your environment:\n\nCreate a python environment: bash     python -m venv venv     source venv/Scripts/activate\nClone the benchmark repo: bash     git clone https://github.com/ssibench/ssibench.git\nInstall DeepInverse bash     pip install deepinv\n\nThen run train.py for your chosen loss, where --loss is one of mc, …:\npython train.py --loss ...\nTo evaluate, use the same script train.py with 0 epochs and loading a checkpoint. We provide one pretrained model for quick eval for TODO\npython train.py --epochs 0 --ckpt \"...pt\"\nNotation: in our benchmark, we compare the loss functions \\(\\mathcal{L}(\\ldots)\\), while keeping constant the model \\(f_\\theta\\), forward operator physics \\(A\\), and data \\(y\\).\n\n\n\n\nAdd the code for your loss in the format: python     class YourOwnLoss(deepinv.loss.Loss):        def forward(             self,              x_net: torch.Tensor,    # Reconstruction i.e. model output             y: torch.Tensor,        # Measurement data e.g. k-space in MRI             x: torch.Tensor = None, # Ground truth, must be unused!             model: deepinv.models.Reconstructor, # Reconstruction model $f_\\theta$             physics: deepinv.physics.Physics,    # Forward operator physics $A$             **kwargs         ):             loss_calc = ...             return loss_calc\nAdd your loss function as an option in train.py (hint: search “Add your custom loss here!”)\nOpen a GitHub pull request to contribute your loss! (hint: how to open a PR in GitHub)\n\n\n\n\nOur modular benchmark lets you easily train and evaluate the benchmarked methods on your own setup.\n\nThe custom dataset should have the form (see DeepInverse docs for details): python     class YourOwnDataset(torch.utils.data.Dataset):         def __getitem__(self, idx: int):             ...             # y = measurement data             # params = dict of physics data-dependent parameters, e.g. acceleration mask in MRI             return     x,     y, params # If ground truth x provided for evaluation             return torch.nan, y, params # If ground truth does not exist\nReplace dataset = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nThe custom model should have the form (see DeepInverse guide for details): python     class YourOwnModel(deepinv.models.Reconstructor):         def forward(             self,              y: torch.Tensor,             physics: deepinv.physics.Physics,             **kwargs         ):             x_net = ...             return x_net\nReplace model = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nTo use an alternative physics, you can use a different off-the-shelf DeepInverse physics or a custom one of the form (see DeepInverse guide on creating custom physics): ```python class YourOwnPhysics(deepinv.physics.Physics): def A(self, x: torch.Tensor, **kwargs): y = … return y\n def A_adjoint(self, y: torch.Tensor, **kwargs):\n     x_hat = ...\n     return x_hat\n```\nReplace physics = ... train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nThe custom metric should have the form (see DeepInverse docs for details): python     class YourOwnMetric(dinv.loss.metric.Metric):         def metric(             self,              x_net: torch.Tensor, # Reconstruction i.e. model output             x: torch.Tensor,     # Ground-truth for evaluation         ):             return ...\nReplace metric = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\n\nTODO\n\n\n\n\nstep by step python …"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "SSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction. We contribute:\n\nA comprehensive review of state-of-the-art self-supervised feedforward methods for inverse problems;\nWell-documented implementations of all benchmarked methods in the open-source DeepInverse library, and a modular benchmark site enabling ML researchers to evaluate new methods or on custom setups and datasets;\nBenchmarking experiments on MRI, across multiple realistic, general scenarios;\nA new method, multi-operator equivariant imaging (MO-EI)."
  },
  {
    "objectID": "index.html#how-to",
    "href": "index.html#how-to",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "First setup your environment:\n\nCreate a python environment: bash     python -m venv venv     source venv/Scripts/activate\nClone the benchmark repo: bash     git clone https://github.com/ssibench/ssibench.git\nInstall DeepInverse bash     pip install deepinv\n\nThen run train.py for your chosen loss, where --loss is one of mc, …:\npython train.py --loss ...\nTo evaluate, use the same script train.py with 0 epochs and loading a checkpoint. We provide one pretrained model for quick eval for TODO\npython train.py --epochs 0 --ckpt \"...pt\"\nNotation: in our benchmark, we compare the loss functions \\(\\mathcal{L}(\\ldots)\\), while keeping constant the model \\(f_\\theta\\), forward operator physics \\(A\\), and data \\(y\\).\n\n\n\n\nAdd the code for your loss in the format: python     class YourOwnLoss(deepinv.loss.Loss):        def forward(             self,              x_net: torch.Tensor,    # Reconstruction i.e. model output             y: torch.Tensor,        # Measurement data e.g. k-space in MRI             x: torch.Tensor = None, # Ground truth, must be unused!             model: deepinv.models.Reconstructor, # Reconstruction model $f_\\theta$             physics: deepinv.physics.Physics,    # Forward operator physics $A$             **kwargs         ):             loss_calc = ...             return loss_calc\nAdd your loss function as an option in train.py (hint: search “Add your custom loss here!”)\nOpen a GitHub pull request to contribute your loss! (hint: how to open a PR in GitHub)\n\n\n\n\nOur modular benchmark lets you easily train and evaluate the benchmarked methods on your own setup.\n\nThe custom dataset should have the form (see DeepInverse docs for details): python     class YourOwnDataset(torch.utils.data.Dataset):         def __getitem__(self, idx: int):             ...             # y = measurement data             # params = dict of physics data-dependent parameters, e.g. acceleration mask in MRI             return     x,     y, params # If ground truth x provided for evaluation             return torch.nan, y, params # If ground truth does not exist\nReplace dataset = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nThe custom model should have the form (see DeepInverse guide for details): python     class YourOwnModel(deepinv.models.Reconstructor):         def forward(             self,              y: torch.Tensor,             physics: deepinv.physics.Physics,             **kwargs         ):             x_net = ...             return x_net\nReplace model = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nTo use an alternative physics, you can use a different off-the-shelf DeepInverse physics or a custom one of the form (see DeepInverse guide on creating custom physics): ```python class YourOwnPhysics(deepinv.physics.Physics): def A(self, x: torch.Tensor, **kwargs): y = … return y\n def A_adjoint(self, y: torch.Tensor, **kwargs):\n     x_hat = ...\n     return x_hat\n```\nReplace physics = ... train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\n\n\nThe custom metric should have the form (see DeepInverse docs for details): python     class YourOwnMetric(dinv.loss.metric.Metric):         def metric(             self,              x_net: torch.Tensor, # Reconstruction i.e. model output             x: torch.Tensor,     # Ground-truth for evaluation         ):             return ...\nReplace metric = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark."
  },
  {
    "objectID": "index.html#benchmark-results",
    "href": "index.html#benchmark-results",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "index.html#training-script-step-by-step",
    "href": "index.html#training-script-step-by-step",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "step by step python …"
  }
]