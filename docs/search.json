[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "",
    "text": "SSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction.\nAndrew Wang, Steven McDonagh, Mike Davies\nSkip to…"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "Overview",
    "text": "Overview\nSSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction. We contribute:\n\nA comprehensive review of state-of-the-art self-supervised feedforward methods for inverse problems;\nWell-documented implementations of all benchmarked methods in the open-source DeepInverse library, and a modular benchmark site enabling ML researchers to evaluate new methods or on custom setups and datasets;\nBenchmarking experiments on MRI, across multiple realistic, general scenarios;\nA new method, multi-operator equivariant imaging (MO-EI)."
  },
  {
    "objectID": "index.html#how-to",
    "href": "index.html#how-to",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "How to…",
    "text": "How to…\n\nHow to use the benchmark\nFirst setup your environment:\n\nCreate a python environment:\n\npython -m venv venv\nsource venv/Scripts/activate\n\nClone the benchmark repo:\n\ngit clone https://github.com/Andrewwango/ssibench.git\n\nInstall DeepInverse\n\npip install deepinv\nThen run train.py for your chosen loss, where --loss is the loss function (mc, ei etc.), and --physics is the physics (see train.py for options):\npython train.py --loss ... --physics ...\nTo evaluate, use the same script train.py with 0 epochs and loading a checkpoint. We provide one pretrained model for quick eval for TODO\npython train.py --epochs 0 --ckpt \"demo_mo-ei.pt\"\nNotation: in our benchmark, we compare the loss functions \\(\\mathcal{L}(\\ldots)\\), while keeping constant the model \\(f_\\theta\\), forward operator physics \\(A\\), and data \\(y\\).\n\n\nHow to contribute a method\n\nAdd the code for your loss in the format:\n\nclass YourOwnLoss(deepinv.loss.Loss):\n    def forward(\n        self, \n        x_net: torch.Tensor,    # Reconstruction i.e. model output\n        y: torch.Tensor,        # Measurement data e.g. k-space in MRI\n        x: torch.Tensor = None, # Ground truth, must be unused!\n        model: deepinv.models.Reconstructor, # Reconstruction model $f_\\theta$\n        physics: deepinv.physics.Physics,    # Forward operator physics $A$\n        **kwargs\n    ):\n        loss_calc = ...\n        return loss_calc\n\nAdd your loss function as an option in train.py (hint: search “Add your custom loss here!”)\nOpen a GitHub pull request to contribute your loss! (hint: how to open a PR in GitHub)\n\n\n\nHow to use a custom dataset\nOur modular benchmark lets you easily train and evaluate the benchmarked methods on your own setup.\n\nThe custom dataset should have the form (see DeepInverse docs for details):\n\nclass YourOwnDataset(torch.utils.data.Dataset):\n    def __getitem__(self, idx: int):\n        ...\n        # y = measurement data\n        # params = dict of physics data-dependent parameters, e.g. acceleration mask in MRI\n        return     x,     y, params # If ground truth x provided for evaluation\n        return torch.nan, y, params # If ground truth does not exist\n\nReplace dataset = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\nHow to use a custom model\n\nThe custom model should have the form (see DeepInverse guide for details):\n\nclass YourOwnModel(deepinv.models.Reconstructor):\n    def forward(\n        self, \n        y: torch.Tensor,\n        physics: deepinv.physics.Physics,\n        **kwargs\n    ):\n        x_net = ...\n        return x_net\n\nReplace model = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\nHow to use a custom forward operator/acquisition strategy\n\nTo use an alternative physics, you can use a different off-the-shelf DeepInverse physics or a custom one of the form (see DeepInverse guide on creating custom physics):\n\nclass YourOwnPhysics(deepinv.physics.Physics):\n    def A(self, x: torch.Tensor, **kwargs):\n        y = ...\n        return y\n    \n    def A_adjoint(self, y: torch.Tensor, **kwargs):\n        x_hat = ...\n        return x_hat\n\nReplace physics = ... train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\nHow to use a custom metric\n\nThe custom metric should have the form (see DeepInverse docs for details):\n\nclass YourOwnMetric(dinv.loss.metric.Metric):\n    def metric(\n        self, \n        x_net: torch.Tensor, # Reconstruction i.e. model output\n        x: torch.Tensor,     # Ground-truth for evaluation\n    ):\n        return ...\n\nReplace metrics = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark."
  },
  {
    "objectID": "index.html#benchmark-results",
    "href": "index.html#benchmark-results",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "Benchmark results",
    "text": "Benchmark results\nTODO"
  },
  {
    "objectID": "index.html#training-script-step-by-step",
    "href": "index.html#training-script-step-by-step",
    "title": "SSIBench: a Self-Supervised Imaging Benchmark",
    "section": "Training script step-by-step",
    "text": "Training script step-by-step\n\n\n\n\n\nThe training script makes extensive use of modular training framework provided by DeepInverse.\n\nimport deepinv as dinv\nimport torch\n\nDefine training parameters:\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\nrng = torch.Generator(device=device).manual_seed(0)\nrng_cpu = torch.Generator(device=\"cpu\").manual_seed(0)\nacceleration = 6\nbatch_size = 4\nlr = 1e-3\nimg_size = (320, 320)\n\nDefine MRI physics \\(A\\) and mask generator \\(M\\) according to scenario\n\nphysics_generator = dinv.physics.generator.GaussianMaskGenerator(img_size=img_size, acceleration=acceleration, rng=rng, device=device)\nphysics = dinv.physics.MRI(img_size=img_size, device=device)\n\nmatch args.physics:\n    case \"noisy\":\n        sigma = 0.1\n        physics.noise_model = dinv.physics.GaussianNoise(sigma, rng=rng)\n    case \"multicoil\":\n        physics = dinv.physics.MultiCoilMRI(img_size=img_size, coil_maps=4, device=device)\n    case \"single\":\n        physics.update(**physics_generator.step())\n\nDefine model \\(f_\\theta\\)\n\ndenoiser = dinv.models.UNet(2, 2, scales=4, batch_norm=False)\nmodel = dinv.models.MoDL(denoiser=denoiser, num_iter=3).to(device)\n\nDefine dataset\n\ndataset = dinv.datasets.SimpleFastMRISliceDataset(\"data\", file_name=\"fastmri_brain_singlecoil.pt\")\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, (0.8, 0.2), generator=rng_cpu)\n\nSimulate and save random measurements\n\ndataset_path = dinv.datasets.generate_dataset(\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    physics=physics,\n    physics_generator=physics_generator if args.physics != \"single\" else None,\n    save_physics_generator_params=True,\n    overwrite_existing=False,\n    device=device,\n    save_dir=\"data\",\n    batch_size=1,\n    dataset_filename=\"dataset_\" + args.physics\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(dataset_path, split=\"train\", load_physics_generator_params=True)\ntest_dataset  = dinv.datasets.HDF5Dataset(dataset_path, split=\"test\",  load_physics_generator_params=True)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=rng_cpu)\ntest_dataloader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size)\n\nDefine loss function (see train.py for all options)\n\nmatch args.loss:\n    case \"mc\":\n        loss = dinv.loss.MCLoss()\n\n    case \"...\":\n        # Add your custom loss here!\n        pass\n\nDefine metrics\n\nmetrics = [\n    dinv.metric.PSNR(complex_abs=True),\n    dinv.metric.SSIM(complex_abs=True)\n]\n\nDefine trainer\n\ntrainer = dinv.Trainer(\n    model = model,\n    physics = physics,\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr),\n    train_dataloader = train_dataloader,\n    eval_dataloader = test_dataloader,\n    epochs = args.epochs,\n    losses = loss,\n    metrics = metrics,\n    device = device,\n    ckpt_pretrained=args.ckpt,\n)\n\n\n\nDefine additional adversarial trainer (if needed)\nif args.loss in (\"uair\", \"adversarial\"):\n    trainer = dinv.training.AdversarialTrainer(\n        model = model,\n        physics = physics,\n        optimizer = dinv.training.AdversarialOptimizer(\n            torch.optim.Adam(model.parameters(), lr=lr), \n            torch.optim.Adam(discrim.parameters(), lr=lr)\n        ),\n        train_dataloader = train_dataloader,\n        eval_dataloader = test_dataloader,\n        epochs = args.epochs,\n        losses = loss,\n        metrics = metrics,\n        device = device,\n        ckpt_pretrained=args.ckpt,\n    )\n\n    trainer.D = discrim\n    trainer.losses_d = loss_d\n\n\nTrain or evaluate!\n\ntrainer.train()\n\nprint(trainer.test(test_dataloader))"
  }
]